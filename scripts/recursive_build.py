
#!/usr/bin/env python3
"""
Recursive Build System for Digital Twin Generation
Creates comprehensive cross-linked Markdown ecosystem
"""

import os
import json
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Set

class RecursiveBuildEngine:
    def __init__(self, outputs_dir: str):
        self.outputs_dir = Path(outputs_dir)
        self.twins_dir = self.outputs_dir / "digital_twins"
        self.metadata_dir = self.outputs_dir / "metadata" 
        self.cross_refs_dir = self.outputs_dir / "cross_references"
        self.build_dir = self.outputs_dir / "recursive_build"
        
        # Create build directory
        self.build_dir.mkdir(exist_ok=True)
        
        self.cross_reference_map = {}
        self.category_index = {}
        self.global_index = {}
    
    def load_all_metadata(self) -> Dict[str, Any]:
        """Load all metadata files"""
        all_metadata = {}
        
        for metadata_file in self.metadata_dir.glob("*_metadata.json"):
            try:
                with open(metadata_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    filename = data.get("original_filename", metadata_file.stem)
                    all_metadata[filename] = data
            except Exception as e:
                print(f"âš ï¸  Could not load {metadata_file}: {e}")
        
        return all_metadata
    
    def load_all_cross_references(self) -> Dict[str, List[Dict]]:
        """Load all cross-reference files"""
        all_cross_refs = {}
        
        for cross_ref_file in self.cross_refs_dir.glob("*_cross_refs.json"):
            try:
                with open(cross_ref_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Extract original filename from cross_ref filename
                    base_name = cross_ref_file.stem.replace('_cross_refs', '')
                    all_cross_refs[base_name] = data
            except Exception as e:
                print(f"âš ï¸  Could not load {cross_ref_file}: {e}")
        
        return all_cross_refs
    
    def build_cross_reference_map(self, all_cross_refs: Dict[str, List[Dict]]) -> None:
        """Build comprehensive cross-reference mapping"""
        for filename, refs in all_cross_refs.items():
            for ref in refs:
                ref_id = ref.get("reference", "")
                if ref_id:
                    if ref_id not in self.cross_reference_map:
                        self.cross_reference_map[ref_id] = []
                    
                    self.cross_reference_map[ref_id].append({
                        "source_file": filename,
                        "context": ref.get("context", ""),
                        "type": ref.get("type", "unknown")
                    })
    
    def build_category_index(self, all_metadata: Dict[str, Any]) -> None:
        """Build category-based index"""
        for filename, metadata in all_metadata.items():
            category = metadata.get("category", "UNKNOWN")
            if category not in self.category_index:
                self.category_index[category] = []
            
            self.category_index[category].append({
                "filename": filename,
                "priority": metadata.get("priority", "MEDIUM"),
                "sub_category": metadata.get("sub_category", ""),
                "processing_date": metadata.get("processing_timestamp", ""),
                "file_hash": metadata.get("file_hash", "")
            })
    
    def generate_master_index(self, all_metadata: Dict[str, Any]) -> str:
        """Generate master index file"""
        content = f"""# Master Index - Digital Twin Ecosystem

Generated: {datetime.now().isoformat()}
Total Documents: {len(all_metadata)}

## ğŸ“Š Overview
This index provides a comprehensive view of all processed documents in the Pipeline Automation Hub ecosystem.

## ğŸ“ Categories
{self._format_category_summary()}

## ğŸ”— Cross-Reference Network
{self._format_cross_reference_network()}

## ğŸ“‘ Document Listing
{self._format_document_listing(all_metadata)}

## ğŸ¯ Navigation
- [Category Index](#categories)
- [Cross-Reference Map](#cross-reference-network)  
- [Document Details](#document-listing)

---
*Master Index generated by Recursive Build Engine*
"""
        return content
    
    def _format_category_summary(self) -> str:
        """Format category summary"""
        lines = []
        for category, files in self.category_index.items():
            count = len(files)
            lines.append(f"- **{category}**: {count} documents")
            
            # Sort by priority
            priority_order = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}
            sorted_files = sorted(files, key=lambda x: priority_order.get(x["priority"], 4))
            
            for file_info in sorted_files[:3]:  # Show top 3
                lines.append(f"  - {file_info['filename']} ({file_info['priority']})")
        
        return "\n".join(lines)
    
    def _format_cross_reference_network(self) -> str:
        """Format cross-reference network"""
        lines = []
        for ref_id, sources in self.cross_reference_map.items():
            lines.append(f"### {ref_id}")
            lines.append(f"Referenced by {len(sources)} documents:")
            
            for source in sources:
                lines.append(f"- **{source['source_file']}**: {source['context']}")
            
            lines.append("")  # Empty line
        
        return "\n".join(lines)
    
    def _format_document_listing(self, all_metadata: Dict[str, Any]) -> str:
        """Format comprehensive document listing"""
        lines = []
        
        # Sort by category and priority
        sorted_docs = []
        for filename, metadata in all_metadata.items():
            priority_score = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}.get(
                metadata.get("priority", "MEDIUM"), 4
            )
            sorted_docs.append((priority_score, filename, metadata))
        
        sorted_docs.sort(key=lambda x: (x[0], x[1]))
        
        for _, filename, metadata in sorted_docs:
            lines.append(f"### {filename}")
            lines.append(f"- **Category**: {metadata.get('category', 'UNKNOWN')}")
            lines.append(f"- **Priority**: {metadata.get('priority', 'MEDIUM')}")
            lines.append(f"- **Sub-category**: {metadata.get('sub_category', 'N/A')}")
            lines.append(f"- **File Hash**: `{metadata.get('file_hash', 'N/A')[:16]}...`")
            lines.append(f"- **Processed**: {metadata.get('processing_timestamp', 'N/A')}")
            
            # Add digital twin link
            twin_name = metadata.get("normalized_name", filename).replace('.pptx', '.md')
            lines.append(f"- **Digital Twin**: [ğŸ“„ {twin_name}](./digital_twins/{twin_name})")
            lines.append("")
        
        return "\n".join(lines)
    
    def enhance_digital_twins(self, all_metadata: Dict[str, Any]) -> None:
        """Enhance digital twins with cross-references and navigation"""
        for twin_file in self.twins_dir.glob("*.md"):
            try:
                # Read existing content
                with open(twin_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Find corresponding metadata
                original_filename = None
                for filename, metadata in all_metadata.items():
                    expected_twin = metadata.get("normalized_name", "").replace('.pptx', '.md')
                    if twin_file.name == expected_twin:
                        original_filename = filename
                        break
                
                if not original_filename:
                    continue
                
                # Add enhanced navigation
                enhanced_content = self._add_navigation_to_twin(content, original_filename, all_metadata)
                
                # Write enhanced version to build directory
                build_twin_path = self.build_dir / twin_file.name
                with open(build_twin_path, 'w', encoding='utf-8') as f:
                    f.write(enhanced_content)
                
            except Exception as e:
                print(f"âš ï¸  Could not enhance {twin_file}: {e}")
    
    def _add_navigation_to_twin(self, content: str, filename: str, all_metadata: Dict[str, Any]) -> str:
        """Add navigation and cross-links to digital twin"""
        metadata = all_metadata.get(filename, {})
        category = metadata.get("category", "UNKNOWN")
        
        # Find related documents in same category
        related_docs = []
        for other_filename, other_metadata in all_metadata.items():
            if (other_filename != filename and 
                other_metadata.get("category") == category):
                twin_name = other_metadata.get("normalized_name", "").replace('.pptx', '.md')
                related_docs.append((other_filename, twin_name))
        
        # Create enhanced navigation section
        navigation_section = f"""
## ğŸ§­ Navigation & Related Documents

### Same Category ({category})
{self._format_related_docs(related_docs)}

### Cross-References
{self._format_document_cross_refs(filename)}

### Global Navigation
- [ğŸ  Master Index](../recursive_build/master_index.md)
- [ğŸ“Š Category: {category}](../recursive_build/category_{category.lower()}.md)
- [ğŸ”— Cross-Reference Network](../recursive_build/cross_reference_network.md)

---
"""
        
        # Insert navigation before the final line
        lines = content.split('\n')
        final_line = lines[-1] if lines and lines[-1].startswith('*Digital Twin generated') else ""
        
        if final_line:
            lines = lines[:-1]  # Remove final line
        
        lines.extend([navigation_section, final_line])
        
        return '\n'.join(lines)
    
    def _format_related_docs(self, related_docs: List[tuple]) -> str:
        """Format related documents list"""
        if not related_docs:
            return "- No related documents in this category"
        
        lines = []
        for original_name, twin_name in related_docs[:5]:  # Limit to 5
            lines.append(f"- [ğŸ“„ {original_name}](./{twin_name})")
        
        return "\n".join(lines)
    
    def _format_document_cross_refs(self, filename: str) -> str:
        """Format cross-references for a specific document"""
        lines = []
        
        # Find all cross-references that mention this document
        for ref_id, sources in self.cross_reference_map.items():
            for source in sources:
                if source["source_file"] == filename.replace('.pptx', ''):
                    lines.append(f"- **{ref_id}**: {source['context']}")
        
        return "\n".join(lines) if lines else "- No cross-references found"
    
    def generate_category_pages(self) -> None:
        """Generate individual category pages"""
        for category, files in self.category_index.items():
            content = f"""# Category: {category}

## Overview
Documents in the {category} category provide {'critical' if any(f['priority'] == 'CRITICAL' for f in files) else 'important'} information for the pipeline automation system.

## Documents ({len(files)})

{self._format_category_documents(files)}

## Statistics
- **Total Documents**: {len(files)}
- **High Priority**: {len([f for f in files if f['priority'] == 'HIGH'])}
- **Critical Priority**: {len([f for f in files if f['priority'] == 'CRITICAL'])}

## Navigation
- [ğŸ  Master Index](./master_index.md)
- [ğŸ”— Cross-Reference Network](./cross_reference_network.md)

---
*Category page generated by Recursive Build Engine*
"""
            
            category_file = self.build_dir / f"category_{category.lower()}.md"
            with open(category_file, 'w', encoding='utf-8') as f:
                f.write(content)
    
    def _format_category_documents(self, files: List[Dict]) -> str:
        """Format documents for category page"""
        lines = []
        
        # Sort by priority
        priority_order = {"CRITICAL": 0, "HIGH": 1, "MEDIUM": 2, "LOW": 3}
        sorted_files = sorted(files, key=lambda x: priority_order.get(x["priority"], 4))
        
        for file_info in sorted_files:
            filename = file_info["filename"]
            priority = file_info["priority"]
            sub_category = file_info["sub_category"]
            
            lines.append(f"### {filename}")
            lines.append(f"- **Priority**: {priority}")
            lines.append(f"- **Sub-category**: {sub_category}")
            lines.append(f"- **Processed**: {file_info['processing_date']}")
            
            # Link to digital twin
            twin_name = filename.replace('.pptx', '.md').replace(' ', '_')
            lines.append(f"- **Digital Twin**: [ğŸ“„ View Document](../digital_twins/{twin_name})")
            lines.append("")
        
        return "\n".join(lines)
    
    def build(self) -> bool:
        """Execute complete recursive build"""
        print("ğŸ—ï¸  Starting Recursive Build Engine...")
        print("-" * 50)
        
        try:
            # Load all data
            print("ğŸ“¥ Loading metadata and cross-references...")
            all_metadata = self.load_all_metadata()
            all_cross_refs = self.load_all_cross_references()
            
            print(f"âœ… Loaded {len(all_metadata)} metadata files")
            print(f"âœ… Loaded {len(all_cross_refs)} cross-reference files")
            
            # Build indexes
            print("ğŸ—ï¸  Building indexes...")
            self.build_cross_reference_map(all_cross_refs)
            self.build_category_index(all_metadata)
            
            print(f"âœ… Built cross-reference map: {len(self.cross_reference_map)} references")
            print(f"âœ… Built category index: {len(self.category_index)} categories")
            
            # Generate master index
            print("ğŸ“‹ Generating master index...")
            master_index = self.generate_master_index(all_metadata)
            master_index_path = self.build_dir / "master_index.md"
            with open(master_index_path, 'w', encoding='utf-8') as f:
                f.write(master_index)
            
            # Generate category pages
            print("ğŸ“ Generating category pages...")
            self.generate_category_pages()
            
            # Enhance digital twins
            print("ğŸ”— Enhancing digital twins with navigation...")
            self.enhance_digital_twins(all_metadata)
            
            print(f"\nâœ… Recursive build completed successfully!")
            print(f"ğŸ“ Build outputs: {self.build_dir}")
            print(f"ğŸ“„ Master index: {master_index_path}")
            
            return True
            
        except Exception as e:
            print(f"âŒ Recursive build failed: {e}")
            return False


if __name__ == "__main__":
    outputs_dir = "/home/ubuntu/pipeline_automation_app/app/public/outputs"
    builder = RecursiveBuildEngine(outputs_dir)
    builder.build()
